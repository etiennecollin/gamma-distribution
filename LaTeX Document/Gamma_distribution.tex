\input{/Users/etiennecollin/Programming/LaTex/Paths}
\path{macOS}

\documentclass[12pt]{article}
\usepackage[english]{babel}																												% Selects language of document
\usepackage{./_assets/Packages}																											% Imports custom packages selection
\usepackage[style=numeric,autocite=superscript,sorting=none,backref=false,backend=biber,date=iso,datezeros=true,seconds=true]{biblatex}	% Bibliography options. autocite=<inline, footnote, superscript, plain>
% \usepackage{indentfirst}																												% Used to indent first paragraph of section

%======================================================================================================================
% DOCUMENT USER SETTINGS ==============================================================================================
%======================================================================================================================
\newcommand{\docAuthorName}{Etienne Collin, Marie Ouellet \& Rania Yahyaoui}
\newcommand{\docAuthorStudentNumber}{}
\newcommand{\docAuthorTitlePage}{\docAuthorName}
\newcommand{\docClass}{Probability and Statistics}
\newcommand{\docClassInstructor}{Professor Vincent Carrier}
\newcommand{\docClassNumber}{201-BNM-LW}
\newcommand{\docClassTime}{Section 20108}
\newcommand{\docClassSemester}{Winter 2022}
\newcommand{\docDueDate}{May 25, 2022}
\newcommand{\docDueTime}{23:59}
\newcommand{\docSubTitle}{Properties, Proofs and Applications}
\newcommand{\docTitle}{The Gamma Distribution}
\input{./_assets/Page_settings.tex}											% Imports custom page settings
\input{./_assets/Environment.tex}											% Imports custom environments and definitions
\fancyhf[HR]{\docClassTime}													% Removes student number from right header
\newcommand{\G}{\mathcal{G}}
\newcommand{\E}{\mathcal{E}}
\newcommand{\N}{\mathcal{N}}
%======================================================================================================================
% SOURCE ==============================================================================================================
%======================================================================================================================
\begin{document}
\singlespacing
\input{_assets/Title_page.tex}
\phantomsection\tableofcontents\pagebreak
\doublespacing
%======================================================================================================================
% START OF DOCUMENT ===================================================================================================
%======================================================================================================================
\section{Historical Context}
The Gamma Distribution is a distribution containing continuous random variables $X$ with two non-negative parameters
$\alpha$ and $\beta$. It is written as
\begin{equation*}
	X\sim\G\text{amma}(\alpha, \lambda)
\end{equation*}
and its density function is
\begin{equation*}
	f(x)=\frac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\lambda x}\text{ for }x\in(0,\infty)
\end{equation*}
A gamma distributed
random variable $X$ is represented by
\begin{equation*}
	X\sim\Gamma(\alpha,\beta)\equiv\Gamma(\alpha,\beta)
\end{equation*}
This distribution gave rise to many other functions and distributions such as the Gamma Function, the Exponential
Distribution, Erlang Distribution, Chi-Square Distribution. This Distribution was firstly presented by Leon Hard Euler,
a Swiss mathematician and physician. As Euler gained popularity, the Gamma Distribution was further researched by
important figures in the domain of mathematics such as Karl Weierstrass, Carl Friedrich Gauss, Charles Hermite, and many
more\cite{hoschGammaDistribution2017, wikipediaGammaDistribution2022, sebahIntroductionGammaFunction2002} .

\pagebreak
\section{Distribution, Variables Defined}
The gamma distribution is part of the two-parameters family of continuous probability distributions. Indeed, it may be
parameterized with two different parameterizations\cite{wikipediaGammaDistribution2022} :

\noindent Parameterization 1:
\vspace*{-24pt}
\begin{align}\label{eq:gamma:parameterization:1}
	\text{Shape: } \alpha>0		&&	\text{Rate: }\lambda>0
\end{align}

\noindent Parameterization 2:
\vspace*{-24pt}
\begin{align}\label{eq:gamma:parameterization:2}
	\text{Shape: } k>0			&&	\text{Scale: }\theta>0
\end{align}

In the second parameterization, the scale parameter $\theta$ corresponds to the inverse of the rate parameter $\lambda$,
allowing flexibility in the modelization of the distribution. Indeed, the application of the scale parameter is
pertinent when one wants to use the value of the mean time between events in the probability density function, as
opposed to the total time until a given number of events occurs.

That being said, in this document, as the two parameterizations only exist for the sake of convenience and are identical
in their results, only the parameterization 1 presented in \autoref{eq:gamma:parameterization:1} will be considered and
used for proofs.

\subsection{Probability density function}\label{section:gamma:pdf}
\begin{equation*}\label{eq:gamma:pdf:2}
	f(x) = \frac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\lambda x}\text{ for }x\in (0,\,\infty)
\end{equation*}
\begin{proof}
	The probability density function of the gamma distribution will be proved using induction. First, take
	\begin{equation*}
		W=\sum^n_{i=1}X_i
	\end{equation*}
	where $W$ is a sum of $n$ i.i.d. random variables following the exponential distribution $\E\text{xp}(\lambda)$.

	\noindent For $n=1$:
	Then, with the induction that $n=\alpha$ works such that:
	Here is the proof that $n=\alpha+1$ works such that:
\end{proof}

\subsection{Moment generating function}
\begin{equation*}\label{eq:gamma-mgf-2}
	M(t) = \left(1-\frac{t}{\lambda}\right)^{-\alpha}\text{ for }t < \lambda
\end{equation*}

\subsection{Expected Value}
The expected value is also known as the theoretical mean:
\begin{equation*}\label{eq:gamma-expected-value-2}
	\mu = E(x) = \frac{\alpha}{\lambda}
\end{equation*}
\begin{proof}
	Using the moment generating function obtained in \autoref{section:gamma:pdf}, the expected value of a gamma
	distribution may be found.
	\begin{equation*}
		\begin{split}
			E(x)		&=	M^\prime(0)\\
			M^\prime(t)	&=	\deriv{t}\left(\frac{\lambda}{\lambda - t}\right)^\alpha\\
						&=	\lambda\alpha\left(\frac{\lambda}{\lambda - t}\right)^{\alpha-1}\deriv{t}\left(\frac{1}{\lambda - t}\right)\\
						&=	\frac{\lambda\alpha}{(\lambda - t)^2}\left(\frac{\lambda}{\lambda - t}\right)^{\alpha-1}\\
			M^\prime(0)	&=	\frac{\lambda\alpha}{\lambda^2}\left(\frac{\lambda}{\lambda}\right)^{\alpha-1}\\
						&=	\frac{\alpha}{\lambda}\\
		\end{split}
	\end{equation*}
\end{proof}

\subsection{Variance}
\begin{equation*}\label{eq:gamma-variance-2}
	\text{Var}(x) = \frac{\alpha}{\lambda^2}
\end{equation*}
\begin{proof}
	Using the moment generating function obtained in \autoref{section:gamma:pdf}, the variance value of a gamma
	distribution may be found.
	\begin{equation*}
		\begin{split}
			E(x)	&=	M^{\prime\prime}(0)\\
		\end{split}
	\end{equation*}
\end{proof}

\subsection{Cumulative distribution function}
\begin{equation*}\label{eq:gamma-cdf-2}
	F(x) = \frac{1}{\Gamma(\alpha)}\gamma(\alpha,\, \lambda x)
\end{equation*}

\subsection{Median}
The median of a probability distribution is the value that separates the area under the curve of its distribution
function in two equal parts. It follows that, in the case of the gamma distribution, the median is defined as the value
$m$ for which:
\begin{equation*}
	\frac{1}{2} = \frac{\lambda^\alpha}{\Gamma(\alpha)} \int^m_0 x^{\alpha-1} e^{-\lambda(x)}\diff{x}
\end{equation*}

However, it is interesting to note that the median of the gamma distribution has no simple closed form : due to its
highly varying shape, it cannot be represented in an equation as a function of its parameters. Although approximations
of the median can be performed for certain ranges of the shape parameter, this topic will not be explored in depth by
this paper. Still, there is comfort in the fact that some special cases of the gamma distribution do have a median, such
as the exponential distribution. Indeed, the median of a continuous random variable following the gamma distribution
such that $X\sim\G\text{amma}(1, \lambda)\equiv\E\text{xp}(\lambda)$ may be obtained through a simple integration
process:
\begin{equation*}
	\begin{split}
		\frac{1}{2}					&=	\frac{\lambda^\alpha}{\Gamma(\alpha)} \int^m_0 x^{\alpha-1} e^{-\lambda x}\diff{x}\\
		\Rightarrow\frac{1}{2}		&=	-e^{-\lambda m} + 1\\
		\Rightarrow\frac{1}{2}		&=	e^{-\lambda m}\\
		\Rightarrow\ln(\frac{1}{2})	&=	-\lambda m\\
		\Rightarrow-\ln(2)			&=	-\lambda m\\
		\Rightarrow m				&=	\frac{\ln(2)}{\lambda}
	\end{split}
\end{equation*}
Hence, the median of an exponential distribution is defined as $\frac{\ln(2)}{\lambda}$.

\subsection{Mode}
\begin{equation*}\label{eq:gamma-mode-2}
	\text{Mode} = \frac{(\alpha-1)}{\lambda}\text{ for }\alpha \geq 1
\end{equation*}

\subsection{Skewness}
\begin{equation*}\label{eq:gamma-skewness-2}
	\text{Skewness} = \frac{2}{\sqrt{\alpha}}
\end{equation*}

\subsection{Excess kurtosis}
\begin{equation*}\label{eq:gamma-kurtosis-2}
	\text{Kurtosis} = \frac{6}{\alpha}
\end{equation*}

\subsection{Entropy}
\begin{equation*}\label{eq:gamma-entropy-2}
	\text{Entropy} = \alpha + \ln{\lambda} + \ln{\Gamma(\alpha)} + (1-\alpha)\psi(\alpha)
\end{equation*}

\subsection{Characteristic function}
\begin{equation*}\label{eq:gamma-cf-2}
	\text{CF} = \left(1-\frac{it}{\lambda}\right)^{-\alpha}
\end{equation*}

\subsection{Methods of moments}
\begin{equation*}\label{eq:gamma-mom-2}
	\begin{split}
		\alpha	&=	\frac{E(X)^2}{\text{Var}(X)}\\
		\lambda	&=	\frac{E(X)}{\text{Var}(X)}
	\end{split}
\end{equation*}

%======================================================================================================================
%======================================================================================================================
%======================================================================================================================

\pagebreak
\section{The Gamma Function}
\vspace*{-6pt}
Studied by Leonhard Euler (1707-1783), the gamma function is related to the gamma distribution. This extremely handy
function allows the generalization of the factorial notation. As a matter of fact, whereas the factorial $\alpha!$ is
restricted to $\alpha\in\mathbb{N}$, the gamma function $\Gamma(\alpha)$ allows the computation of fractional and
negative numbers such that $\alpha\in\mathbb{Q}$. By abusing the notation, the gamma function may even be used to
compute $\Gamma(\alpha)$ such that $\alpha\in\mathbb{R}$. The relationship between the gamma function and the factorial
notation is as follows:
\vspace*{-18pt}
\begin{equation}\label{eq:gammafunction:factorial}
	\Gamma(\alpha)=(\alpha-1)!
\end{equation}
\vspace*{-60pt}

\subsection{Definition}\label{sect:gammafunction:definition}
\vspace*{-6pt}
First of all, the gamma function is defined as:
\vspace*{-12pt}
\begin{equation*}
	\Gamma(\alpha)=\int^\infty_0 x^{\alpha-1}e^{-x}\diff{x} \textnormal{ for }\alpha\in\mathbb{R}^+
\end{equation*}\\[-36pt]
Assuming that $\alpha > 1$, the closed form of the Gamma function may be found with integration by parts:\\[-12pt]
\begin{empheq}[box=\widefbox]{align*}
	u=x^{\alpha-1};						&&\,	\diff{v}=e^{-x}\\
	\diff{u}=(\alpha-1)x^{\alpha-2};	&&\,	v=-e^{-x}
\end{empheq}
\begin{equation*}
	\begin{split}
		\Gamma(\alpha)	&=	\int^\infty_0 x^{\alpha-1}e^{-x}\diff{x}\\
						&=	-\left[x^{\alpha-1}e^{-x}\right]^\infty_0 + (\alpha-1)\int^\infty_0 x^{\alpha-2}e^{-x}\diff{x}\\
						&=	0+(\alpha-1)\Gamma(\alpha-1)\\
						&=	(\alpha-1)\Gamma(\alpha-1)
	\end{split}
\end{equation*}
Therefore,
\begin{equation}\label{eq:gammafunction:closedform}
	\Gamma(\alpha)	=	(\alpha-1)\Gamma(\alpha-1)\textnormal{ for }\alpha\in(1,\infty)
\end{equation}
Furthermore, $\Gamma(1)$ is defined separately as being:
\vspace*{-12pt}
\begin{equation*}
	\Gamma(1) = \int^\infty_0 e^{-x}\diff{x} = \left[-e^{-x}\right]^\infty_0 = 1
\end{equation*}

%======================================================================================================================
%======================================================================================================================
%=================================================================================================================

\pagebreak
\subsubsection{Special case of $\Gamma(\sfrac{1}{2})$ \bigred{Add proof}}
An extremely case of the gamma function is $\Gamma(\sfrac{1}{2})$. In fact, this result allows the computation of
fractional values of $\alpha$ such that $\alpha\in\mathbb{Q}$. This special case is as follows:
\begin{equation}\label{eq:gammafunction:onehalf}
	\Gamma(\sfrac{1}{2})=\sqrt{\pi}
\end{equation}
\begin{proof}
	Here is a proof for \autoref{eq:gammafunction:onehalf}.
	\begin{equation*}
		x
	\end{equation*}
\end{proof}

%======================================================================================================================
%======================================================================================================================
%======================================================================================================================

\pagebreak
\subsubsection{Negative values of $\alpha$}
As was mentioned earlier, by abusing this identity shown in \autoref{eq:gammafunction:closedform}, one may extend the
gamma function to negative non-integer values of $\alpha$ such that $\alpha\in\mathbb{R}\,\backslash\mathbb{Z}^-$. For
example, to find $\Gamma(-\sfrac{9}{2})$, one may compute:
\vspace*{-12pt}
\begin{equation*}
	\begin{split}
		\Gamma(\sfrac{1}{2})	&=	(-\sfrac{1}{2})\Gamma(-\sfrac{1}{2})\\
								&=	(-\sfrac{1}{2})(-\sfrac{3}{2})\Gamma(-\sfrac{3}{2})\\
								&=	(\sfrac{3}{4})(-\sfrac{5}{2})\Gamma(-\sfrac{5}{2})\\
								&=	(-\sfrac{15}{8})(-\sfrac{7}{2})\Gamma(-\sfrac{7}{2})\\
								&=	(\sfrac{105}{16})(-\sfrac{9}{2})\Gamma(-\sfrac{9}{2})\\
								&=	(-\sfrac{945}{32})\Gamma(-\sfrac{9}{2})\\
	\end{split}
\end{equation*}
\begin{equation*}
	\therefore\Gamma(-\sfrac{9}{2})=-\frac{32}{945}\Gamma(\sfrac{1}{2})=-\frac{32}{945}\sqrt{\pi}
\end{equation*}
Hence, to calculate the value of a gamma function with a negative argument, one might modify a bit the result obtained
in \autoref{eq:gammafunction:closedform} such that:
\vspace*{-12pt}
\begin{equation*}
	\Gamma(\alpha)=\frac{\Gamma(\alpha+1)}{\alpha}\text{ for }\alpha\in\mathbb{R}^-\,\backslash\mathbb{Z}
\end{equation*}\\[-36pt]
for example, take the same example of $\Gamma(-\sfrac{9}{2})$\\[-12pt]
\begin{equation*}
	\begin{split}
		\Gamma(-\sfrac{9}{2})	&=	\frac{\Gamma(-\sfrac{7}{2})}{(-\sfrac{9}{2})}\\
								&=	\frac{\Gamma(-\sfrac{5}{2})}{(-\sfrac{9}{2})(-\sfrac{7}{2})}\\
								&=	\frac{\Gamma(-\sfrac{3}{2})}{(\sfrac{63}{4})(-\sfrac{5}{2})}\\
								&=	\frac{\Gamma(-\sfrac{1}{2})}{(-\sfrac{315}{8})(-\sfrac{3}{2})}\\
								&=	\frac{\Gamma(\sfrac{1}{2})}{(\sfrac{945}{16})(-\sfrac{1}{2})}\\
								&=	\frac{\Gamma(\sfrac{1}{2})}{(-\sfrac{945}{32})}
		\end{split}
\end{equation*}
\begin{equation*}
	\therefore\Gamma(-\sfrac{9}{2})=-\frac{32}{945}\Gamma(\sfrac{1}{2})=-\frac{32}{945}\sqrt{\pi}
\end{equation*}

%======================================================================================================================
%======================================================================================================================
%======================================================================================================================

\pagebreak
\subsection{Relationship to Factorial Notation}
Using the equations found in \autoref{sect:gammafunction:definition}, the value of other gamma functions may be
calculated to prove \autoref{eq:gammafunction:factorial}:
\begin{equation*}
	\begin{split}
		\Gamma(2)	&=	1\cdot\Gamma(1)	=	1	=	1!\\
		\Gamma(3)	&=	2\cdot\Gamma(2)	=	2	=	2!\\
		\Gamma(4)	&=	3\cdot\Gamma(3)	=	6	=	3!\\
		\Gamma(5)	&=	4\cdot\Gamma(4)	=	24	=	4!\\
		\Gamma(6)	&=	5\cdot\Gamma(5)	=	120	=	5!
	\end{split}
\end{equation*}
Indeed, these results show that:
\begin{equation*}
	\Gamma(\alpha)=(\alpha-1)!\text{ for }\alpha\in\mathbb{N}
\end{equation*}

%======================================================================================================================
%======================================================================================================================
%======================================================================================================================

\pagebreak
\subsection{Conclusion}
Using everything that was computed previously, the graph of $\Gamma(\alpha)$ may be plotted. It includes both positive,
negative and fractional values of $\alpha$. Notice how the asymptotes of the graph are every negative integer; the
function, as was mentioned previously, is not defined for negative integers.
\figurecenter{1}{gamma_function.png}{Graph featuring the plot of the function $\Gamma(\alpha)$ in red and the asymptotes of the function in dotted blue lines.}{fig:graph:gammafunction}

%======================================================================================================================
%======================================================================================================================
%======================================================================================================================

\pagebreak
\section{General Applications and Family}\label{section:generalApplications}

The gamma distribution is used in many fields, since it is directly related to the Erlang, normal and exponential
distributions whose contributions extend to several disciplines. Here, we will present some of those applications.

\subsection{Insurance Companies}
First, the gamma distribution is of great use in the field of insurance services, given its direct relation to the
exponential distribution. For example, an analyst could use this distribution to specify the amount of time a product
lasts if one uses it at a constant average rate, thus modeling how reliable it is (and how much insurance should be
charged for it). Then, the size of loan defaults and the cost of insurance claims are also often modeled according to a
gamma distribution.

\subsection{Natural Events Prediction}
Then, the gamma distribution can also be used to model the amount of rainfall accumulated in a given reservoir. Indeed,
this distribution fits positive data, represents rainfall distribution well and its two parameters -shape and scale-
give it sufficient flexibility to fit various climates\cite{husakUseGammaDistribution2007a}.

\subsection{Customer Satisfaction}
Service time can also be modeled using the gamma distribution. For example, if one is waiting in line for a meal, the
waiting time until one receives the long-awaited food can be modelled using an exponential distribution. Using the same
principle, the Erlang distribution can allow one to determine the total length of a process, that is, the duration of a
sequence of independent events. For instance, if a large number of people are waiting in line to be served, the
distribution of each of their individual waiting times (the sum of several independent exponentially distributed
variables) will correspond to the time it takes for the employee to serve everyone in it. Therefore, the gamma
distribution lies at the heart of what is called queuing theory: the mathematical study of the congestion of waiting
lines. Since waiting lines are found in countless places such as banks, restaurants and hospitals, as well as on web
servers or multistep manufacturing and distribution processes, the gamma distribution provides very useful applications
in everyday life.

\subsection{Call Centers}
One of the most famous of those applications concerns phone queuing, on which A. K. Erlang famously worked. The Erlang
distribution has indeed been developed in the goal to model the time in between incoming calls at a call center, along
with the expected number of calls, thus allowing call centers to know what their staffing capacity should be depending
on the time of day.

Beyond waiting lines, the Erlang distribution is often used by retailers to model the frequency of interpurchase times
by consumers, which gives them an idea of how often a given consumer is expected to purchase a product from them and
helps them control inventory and staffing.

\subsection{Oncology}
Finally, in the field of oncology, the age distribution of cancer incidence also follows a gamma distribution. Although
the factors underlying cancer development are not yet fully understood, it has been hypothesized that cancers arise
after several successive “driver events”, that is, after some number of mutations occurs in a cell. Analyses of cancer
statistics suggest that the incidence of the most prevalent cancer types with respect to the patients' age closely
follows the gamma probability distribution or, more specifically, the Erlang distribution. This may be due to the fact
that, more broadly, the Erlang distribution can be used to model cell cycle time
distribution\cite{belikovNumberKeyCarcinogenic2017} .

\begin{equation*}
	Y = A\cdot x^{k-1}\frac{e^{\frac{-x}{b}}}{b^k}\cdot\Gamma(k)
\end{equation*}

In this case, the shape parameter $\alpha$ predicts the number of carcinogenic driver events, whereas the shape
parameter $\lambda$ predicts the average time between those events for each cancer type. Using an additional amplitude
parameter A, the maximal population susceptibility to a given type of cancer can even be
predicted\cite{belikovNumberKeyCarcinogenic2017}. Given that experimental research on cancer development is crucial for
the lives of many people, numerical references such as that provided by the gamma distribution are of paramount
importance in our society. The gamma distribution can save lives, if it is used wisely!

\figurecenter{1}{Cancer_probability}{"The Erlang distribution approximates cancer incidence by age for 20 most prevalentcancer types. Dots indicate actual data for 5-year age intervals, curves indicate the PDF of the Erlang distribution fitted to the data [...]. The middle age of each age group is plotted. Cancer types are arranged in the order of decreasing incidence"\cite{belikovNumberKeyCarcinogenic2017} .}{fig:cancerProbability}

%======================================================================================================================
%======================================================================================================================
%======================================================================================================================

\pagebreak
\section{Special Cases of the Gamma Distribution}
The gamma distribution has many common parameterizations. Hence, in order to make working with them easier, they were
given a specific name such as the chi-square distribution, the exponential distribution and more. In this section, we
will present some of these special cases and prove their relationship.

\subsection{The Erlang Distribution}
In real world applications, it is often useful to limit the number of occurrences to a positive integer (it may not be
pertinent to determine, for example, the waiting time until 2.665 events take place). In this context, the special name
“Erlang distribution” has been attributed to the specific gamma distribution in which the shape parameter $\alpha$ only
takes positive integer values and where the rate parameter $\lambda$ is a positive real number.
\begin{equation*}
	f_{X_\alpha}(x)	= 	\begin{cases}
							\dfrac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\lambda x}  & \alpha\in\mathbb{N}; x\geq0\\
							0  & x<0
  						\end{cases}
\end{equation*}

This distribution takes its name from A. K. Erlang, the man who initially popularized its use in order to examine the
number of telephone calls which can be made at the same time to the operators of the switching stations, in the field of
phone traffic engineering. Indeed, the Erlang distribution's original purpose was to measure the time between incoming
calls, a statistic which can be used along with the expected duration of incoming calls to analyze phone traffic loads.
His work has since been expanded to consider queuing systems in general, as well as the load on web servers,
interpurchase times and cancer incidence (see \autoref{section:generalApplications})\cite{zachWhatErlangDistribution2020}.

%======================================================================================================================
%======================================================================================================================
%======================================================================================================================

\pagebreak
\subsection{The Exponential Distribution}
The gamma distribution can model the elapsed time between random and independent events. However, what should one do
when they want to strictly model the time to wait before a new event?

If a unique event is modeled, it follows that the shape parameter is limited to $\alpha = 1$. In such a case, the gamma
distribution is said to follow an exponential distribution: more specifically, if $X\sim\G\text{amma}(1, \lambda)$, then
it can also be said that $X\sim\E\text{xp}(\lambda)$. $X$ thus follows an exponential distribution with rate parameter
$\lambda$, where the rate parameter represents how quickly events occur. More concretely:
\begin{equation*}
	X\sim\G\text{amma}(1, \lambda)\equiv\E\text{xp}(\lambda)
\end{equation*}
\bigred{MAYBE HERE INCLUDE GRAPH OF GAMMA DISTRIBUTION WITH SHAPE PARAMETER 1  COMPARED TO OTHER SHAPE PARAMETERS ?}
Indeed, using a simple substitution of the variables, one gets that:
\begin{equation*}\label{eq:relation:exp}
	\begin{split}
		f(x)	&=	\frac{\lambda^\alpha x^{\alpha-1}}{\Gamma(\alpha)}e^{-\lambda x}\\
				&=	\frac{\lambda^1 x^{0}}{\Gamma(1)}e^{-\lambda x}\\
				&=	\lambda e^{-\lambda x}
	\end{split}
\end{equation*}
\begin{equation*}
	\therefore X\sim\G\text{amma}(1, \lambda)\equiv X\sim\E\text{xp}(\lambda)
\end{equation*}
Accordingly, it can be demonstrated that the sum of exponential random variables is a gamma random variable. That is:
\begin{equation*}
	\text{If } X_1,\,X_2,\,\ldots,\,X_n \text{ are i.i.d random variables following } \E\text{xp}(\lambda)\text{, then }Y=\sum^k_{i=1}\left[X_i\right]\sim\G\text{amma}(k, \lambda)
\end{equation*}
\begin{proof}
	\bigred{ADD HERE PROOF FOR THE DENSITY FUNCTION OF THE SUM OF EXPONENTIAL RANDOM VARIABLES (ETIENNE'S PART)}
	\begin{equation*}
		XYZ
	\end{equation*}
\end{proof}

%======================================================================================================================
%======================================================================================================================
%======================================================================================================================

\pagebreak
\subsection{The Chi-Squared Distribution}
Then, the gamma distribution with parameters $\alpha=\sfrac{n}{2}$ and $\lambda=\sfrac{1}{2}$ is called the
chi-squared distribution with $n$ degrees of freedom such that
\begin{equation*}
	X\sim\G\text{ammma}(\sfrac{n}{2}, \sfrac{1}{2})\equiv\chi^2_n
\end{equation*}
\begin{proof}
	First, to show that $\G\text{ammma}(\sfrac{n}{2},\sfrac{1}{2})\equiv\chi^2_n$, let's prove that
	$\G\text{ammma}(\sfrac{1}{2},\sfrac{1}{2})\equiv\chi^2_1$, a chi-squared distribution with one (1) degree of
	freedom, using a change of variables with $Y=Z^2$ for $Y\sim\chi^2_1$.
	\begin{equation*}\label{eq:relation:chisquared:1}
		\begin{split}
			G(y)	&=	P(Y\leq y)\\
					&=	P(Z^2\leq y)\\
					&=	P(-\sqrt{y}\leq z \leq \sqrt{y})\\
					&=	\Phi(\sqrt{y})-\Phi(-\sqrt{y})\\[12pt]
			g(y)	&=	\frac{f(\sqrt{y})}{2\sqrt{y}}+\frac{f(-\sqrt{y})}{2\sqrt{y}}\\
					&=	\frac{e^{-\sfrac{y}{2}}}{2\sqrt{2\pi y}} + \frac{e^{-\sfrac{y}{2}}}{2\sqrt{2\pi y}}\\
					&=	\frac{\cancel{2}e^{-\sfrac{y}{2}}}{\cancel{2}\sqrt{2\pi y}}\\
					&=	\frac{1}{\sqrt{2}\Gamma(\frac{1}{2})}y^{-\sfrac{1}{2}}e^{-y\sfrac{1}{2}}\\
					&=	\frac{(\frac{1}{2})^{\sfrac{1}{2}}}{\Gamma(\frac{1}{2})}y^{\sfrac{1}{2}-1}e^{-(\sfrac{1}{2})y}
			\end{split}
	\end{equation*}
	\begin{equation*}
		\therefore Y\sim\G\text{ammma}(\sfrac{1}{2}, \sfrac{1}{2})\equiv\chi^2_1
	\end{equation*}
	One may generalize this result by using that $Z_1,\,Z_2,\,\ldots,\,Z_n$ are i.i.d. random variables following $\N(0,
	1)$ to find the distribution of
	\begin{equation*}
		Y = \sum^n_{i=1}Z^2_i
	\end{equation*}
	Hence, using the moment generating function,
	\begin{equation*}\label{eq:relation:chisquared:n}
		\begin{split}
			M_{\sum^n_{i=1}Z^2_i}(t)	&=	\prod^n_{i=1}M_{Z^2_i}(t)\\
										&=	M(t)^n\\
										&=	\left(\frac{\sfrac{1}{2}}{\sfrac{1}{2}-t}\right)^{\displaystyle\sfrac{n}{2}}
		\end{split}
	\end{equation*}
	This last line is equal to the moment generating function of a random variable following the distribution
	$\G\text{amma}(\sfrac{n}{2}, \sfrac{1}{2})$. Hence,
	\begin{equation*}
		\therefore Y\sim\G\text{amma}(\sfrac{n}{2}, \sfrac{1}{2})\equiv \chi^2_n
	\end{equation*}
\end{proof}

Using the result proved previously, the density function of the chi-squared distribution may be determined by
substituting the parameters $\alpha = \sfrac{n}{2}$ and $\lambda = \sfrac{1}{2}$ into the density function of the gamma
distribution:
\begin{equation*}\label{eq:chisquared-density}
	\begin{split}
		f(x)	&=	\frac{\lambda^\alpha}{\Gamma(\alpha)}x^{\alpha-1}e^{-\lambda x}\\
				&=	\frac{(\frac{1}{2})^{\sfrac{n}{2}}}{\Gamma(\frac{n}{2})}x^{\frac{n}{2}-1}e^{-\frac{1}{2}x}\\
				&=	\frac{1}{2^{\sfrac{n}{2}}\Gamma(\frac{n}{2})}x^{\frac{n}{2}-1}e^{-\sfrac{x}{2}}
	\end{split}
\end{equation*}

\bigred{HERE INCLUDE GRAPH OF CHI SQUARE DISTRIBUTIONS}

The chi square distribution is often used to describe the distribution of a sum of squared random variables, to test the
fit of a distribution of data or to determine whether data series are independent or dependent.

\subsection{The Normal Distribution}
Text on the normal distribution

%======================================================================================================================
%======================================================================================================================
%======================================================================================================================

\pagebreak
\subsection{The Beta Distribution}
Text on the Beta distribution

%======================================================================================================================
%======================================================================================================================
%======================================================================================================================

\pagebreak
\subsection{The Wishart Distribution}
Text on the Wishart distribution

%======================================================================================================================
% END OF DOCUMENT =====================================================================================================
%======================================================================================================================
\pagebreak

\begin{appendix}
\phantomsection\listoffigures
\phantomsection\listoftables
\end{appendix}

\pagebreak\phantomsection\printbibliography[heading=bibintoc,title={References}]
\end{document}

\begin{tabular}
